Comparisons :
['33']
{'LEC': {'micro': [1, 2, 3, 4, 5, 6, 7, 8], 'macro': [15, 16, 17, 18, 19, 20, 21]}, 'LPHG': {'micro': [25, 26, 27, 28, 29, 30, 31, 32], 'macro': [45, 46, 47, 48, 49, 50, 51, 52]}, 'LAH': {'micro': [9, 10, 11, 12, 13, 14, 15, 16], 'macro': [8, 9, 10, 11, 12, 13, 14]}, 'LA': {'micro': [17, 18, 19, 20, 21, 22, 23, 24], 'macro': [1, 2, 3, 4, 5, 6, 7]}, 'RAH': {'micro': [73, 74, 75, 76, 77, 78, 79], 'macro': [60, 61, 62, 63, 64, 65, 66]}, 'RIO': {'micro': [80, 81, 82, 83, 84, 85, 86, 87], 'macro': [74, 75, 76, 77, 78, 79, 80, 81]}, 'LIO': {'micro': [57, 58, 59, 60, 61, 62, 63, 64], 'macro': [22, 23, 24, 25, 26, 27, 28, 29]}, 'LIP': {'micro': [41, 42, 43, 44, 45, 46, 47, 48], 'macro': [30, 31, 32, 33, 34, 35, 36, 37]}, 'LSTG': {'micro': [33, 34, 35, 36, 37, 38, 39, 40], 'macro': [53, 54, 55, 56, 57, 58, 59]}, 'REC': {'micro': [65, 66, 67, 68, 69, 70, 71, 72], 'macro': [67, 68, 69, 70, 71, 72, 73]}, 'LO': {'micro': [49, 50, 51, 52, 53, 54, 55, 56], 'macro': [38, 39, 40, 41, 42, 43, 44]}, 'MICROPHONE': {'micro': [0]}}
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/micro -patient 482 --micro-macro micro -channel 1 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/micro -patient 482 --micro-macro micro -channel 2 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/micro -patient 482 --micro-macro micro -channel 3 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/micro -patient 482 --micro-macro micro -channel 4 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/micro -patient 482 --micro-macro micro -channel 5 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/micro -patient 482 --micro-macro micro -channel 6 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/micro -patient 482 --micro-macro micro -channel 7 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/micro -patient 482 --micro-macro micro -channel 8 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro LEC --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/micro
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/macro -patient 482 --micro-macro macro -channel 15 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro LEC --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/micro
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike -patient 482 -channel 1 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"Namespace(SOA=500, align=[], baseline=None, block=[], channel=1, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_1-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_1-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_1-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~289 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike/raster_UCLA_patient_482_p_g4_1_LEC1_ch_1_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=1, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_1-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_1-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_1-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike/raster_UCLA_patient_482_p_g4_1_LEC1_ch_1_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=2, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_2-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_2-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_2-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~289 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike/raster_UCLA_patient_482_p_g3_2_LEC2_ch_2_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=2, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_2-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_2-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_2-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike/raster_UCLA_patient_482_p_g3_2_LEC2_ch_2_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=3, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_3-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_3-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_3-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~289 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike/raster_UCLA_patient_482_p_g1_3_LEC3_ch_3_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=3, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_3-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_3-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LEC_ch_3-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike/raster_UCLA_patient_482_p_g1_3_LEC3_ch_3_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=4, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=4, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=5, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=5, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=6, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=6, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=7, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=7, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=8, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=8, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []

--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike -patient 482 -channel 1 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike -patient 482 -channel 2 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike -patient 482 -channel 2 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike -patient 482 -channel 3 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike -patient 482 -channel 3 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike -patient 482 -channel 4 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike -patient 482 -channel 4 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike -patient 482 -channel 5 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike -patient 482 -channel 5 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike -patient 482 -channel 6 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike -patient 482 -channel 6 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike -patient 482 -channel 7 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike -patient 482 -channel 7 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike -patient 482 -channel 8 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike -patient 482 -channel 8 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro none --picks-macro none --picks-spike LEC --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LEC/spike
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/micro -patient 482 --micro-macro micro -channel 25 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/micro -patient 482 --micro-macro micro -channel 26 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/micro -patient 482 --micro-macro micro -channel 27 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/micro -patient 482 --micro-macro micro -channel 28 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/micro -patient 482 --micro-macro micro -channel 29 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"Namespace(SOA=500, align=[], baseline=None, block=[], channel=25, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=25, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=26, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=26, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=27, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LPHG_ch_27-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LPHG_ch_27-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LPHG_ch_27-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~290 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike/raster_UCLA_patient_482_p_g1_27_LPHG3_ch_27_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=27, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LPHG_ch_27-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LPHG_ch_27-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LPHG_ch_27-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike/raster_UCLA_patient_482_p_g1_27_LPHG3_ch_27_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=28, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=28, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=29, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=29, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=30, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=30, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=31, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=31, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=32, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []

--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/micro -patient 482 --micro-macro micro -channel 30 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/micro -patient 482 --micro-macro micro -channel 31 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/micro -patient 482 --micro-macro micro -channel 32 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro LPHG --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/micro
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/macro -patient 482 --micro-macro macro -channel 45 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro LPHG --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/micro
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike -patient 482 -channel 25 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike -patient 482 -channel 25 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike -patient 482 -channel 26 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike -patient 482 -channel 26 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike -patient 482 -channel 27 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike -patient 482 -channel 27 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike -patient 482 -channel 28 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike -patient 482 -channel 28 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike -patient 482 -channel 29 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike -patient 482 -channel 29 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike -patient 482 -channel 30 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike -patient 482 -channel 30 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike -patient 482 -channel 31 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike -patient 482 -channel 31 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike -patient 482 -channel 32 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike -patient 482 -channel 32 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"Namespace(SOA=500, align=[], baseline=None, block=[], channel=32, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=9, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=9, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=10, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []

--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro none --picks-macro none --picks-spike LPHG --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LPHG/spike
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/micro -patient 482 --micro-macro micro -channel 9 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/micro -patient 482 --micro-macro micro -channel 10 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/micro -patient 482 --micro-macro micro -channel 11 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/micro -patient 482 --micro-macro micro -channel 12 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/micro -patient 482 --micro-macro micro -channel 13 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/micro -patient 482 --micro-macro micro -channel 14 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/micro -patient 482 --micro-macro micro -channel 15 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/micro -patient 482 --micro-macro micro -channel 16 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro LAH --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/micro
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/macro -patient 482 --micro-macro macro -channel 8 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro LAH --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/micro
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike -patient 482 -channel 9 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike -patient 482 -channel 9 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike -patient 482 -channel 10 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------Namespace(SOA=500, align=[], baseline=None, block=[], channel=10, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=11, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=11, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=12, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=12, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=13, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LAH_ch_13-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LAH_ch_13-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LAH_ch_13-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~289 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike/raster_UCLA_patient_482_p_g1_13_LAH5_ch_13_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=13, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LAH_ch_13-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LAH_ch_13-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LAH_ch_13-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike/raster_UCLA_patient_482_p_g1_13_LAH5_ch_13_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=14, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=14, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=15, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=15, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=16, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=16, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []

python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike -patient 482 -channel 10 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike -patient 482 -channel 11 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike -patient 482 -channel 11 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike -patient 482 -channel 12 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike -patient 482 -channel 12 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike -patient 482 -channel 13 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike -patient 482 -channel 13 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike -patient 482 -channel 14 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike -patient 482 -channel 14 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike -patient 482 -channel 15 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike -patient 482 -channel 15 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike -patient 482 -channel 16 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike -patient 482 -channel 16 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro none --picks-macro none --picks-spike LAH --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LAH/spike
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/micro -patient 482 --micro-macro micro -channel 17 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/micro -patient 482 --micro-macro micro -channel 18 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/micro -patient 482 --micro-macro micro -channel 19 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/micro -patient 482 --micro-macro micro -channel 20 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/micro -patient 482 --micro-macro micro -channel 21 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/micro -patient 482 --micro-macro micro -channel 22 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"Namespace(SOA=500, align=[], baseline=None, block=[], channel=17, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_17-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_17-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_17-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~289 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g2_17_LA1_ch_17_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=17, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_17-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_17-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_17-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g2_17_LA1_ch_17_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=18, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_18-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_18-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_18-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~573 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g1_18_LA2_ch_18_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g2_18_LA2_ch_18_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=18, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_18-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_18-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_18-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~854 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g1_18_LA2_ch_18_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g2_18_LA2_ch_18_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=19, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_19-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_19-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_19-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~573 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g1_19_LA3_ch_19_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g2_19_LA3_ch_19_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=19, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_19-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_19-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_19-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~854 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g1_19_LA3_ch_19_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g2_19_LA3_ch_19_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=20, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_20-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_20-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_20-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~289 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g1_20_LA4_ch_20_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=20, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_20-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_20-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_20-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g1_20_LA4_ch_20_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=21, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=21, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=22, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_22-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_22-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_22-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~1.4 MB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g1_22_LA6_ch_22_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g2_22_LA6_ch_22_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g3_22_LA6_ch_22_cluster_2_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g4_22_LA6_ch_22_cluster_3_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g5_22_LA6_ch_22_cluster_4_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=22, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_22-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_22-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_22-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~2.1 MB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g1_22_LA6_ch_22_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g2_22_LA6_ch_22_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g3_22_LA6_ch_22_cluster_2_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g4_22_LA6_ch_22_cluster_3_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g5_22_LA6_ch_22_cluster_4_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=23, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_23-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_23-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_23-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~289 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g1_23_LA7_ch_23_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=23, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_23-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_23-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LA_ch_23-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike/raster_UCLA_patient_482_p_g1_23_LA7_ch_23_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=24, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=24, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []

--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/micro -patient 482 --micro-macro micro -channel 23 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/micro -patient 482 --micro-macro micro -channel 24 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro LA --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/micro
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/macro -patient 482 --micro-macro macro -channel 1 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro LA --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/micro
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike -patient 482 -channel 17 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike -patient 482 -channel 17 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike -patient 482 -channel 18 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike -patient 482 -channel 18 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike -patient 482 -channel 19 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike -patient 482 -channel 19 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike -patient 482 -channel 20 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike -patient 482 -channel 20 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike -patient 482 -channel 21 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike -patient 482 -channel 21 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike -patient 482 -channel 22 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike -patient 482 -channel 22 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike -patient 482 -channel 23 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike -patient 482 -channel 23 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike -patient 482 -channel 24 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike -patient 482 -channel 24 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro none --picks-macro none --picks-spike LA --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LA/spike
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/micro -patient 482 --micro-macro micro -channel 73 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"Namespace(SOA=500, align=[], baseline=None, block=[], channel=73, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_73-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_73-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_73-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~856 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g1_73_RAH1_ch_73_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g2_73_RAH1_ch_73_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g3_73_RAH1_ch_73_cluster_2_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=73, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_73-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_73-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_73-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~1.2 MB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g1_73_RAH1_ch_73_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g2_73_RAH1_ch_73_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g3_73_RAH1_ch_73_cluster_2_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=74, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=74, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=75, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_75-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_75-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_75-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~856 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g1_75_RAH3_ch_75_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g2_75_RAH3_ch_75_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g3_75_RAH3_ch_75_cluster_2_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=75, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_75-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_75-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_75-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~1.2 MB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g1_75_RAH3_ch_75_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g2_75_RAH3_ch_75_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g3_75_RAH3_ch_75_cluster_2_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=76, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_76-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_76-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_76-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~1.1 MB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g1_76_RAH5_ch_76_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g2_76_RAH5_ch_76_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g3_76_RAH5_ch_76_cluster_2_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g4_76_RAH5_ch_76_cluster_3_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=76, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_76-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_76-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_76-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~1.7 MB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g1_76_RAH5_ch_76_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g2_76_RAH5_ch_76_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g3_76_RAH5_ch_76_cluster_2_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g4_76_RAH5_ch_76_cluster_3_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:

--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/micro -patient 482 --micro-macro micro -channel 74 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/micro -patient 482 --micro-macro micro -channel 75 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/micro -patient 482 --micro-macro micro -channel 76 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/micro -patient 482 --micro-macro micro -channel 77 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/micro -patient 482 --micro-macro micro -channel 78 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/micro -patient 482 --micro-macro micro -channel 79 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro RAH --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/micro
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/macro -patient 482 --micro-macro macro -channel 60 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro RAH --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/micro
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike -patient 482 -channel 73 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike -patient 482 -channel 73 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike -patient 482 -channel 74 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike -patient 482 -channel 74 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike -patient 482 -channel 75 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike -patient 482 -channel 75 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike -patient 482 -channel 76 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike -patient 482 -channel 76 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike -patient 482 -channel 77 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"Namespace(SOA=500, align=[], baseline=None, block=[], channel=77, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_77-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_77-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_77-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~856 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g1_77_RAH6_ch_77_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g2_77_RAH6_ch_77_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g3_77_RAH6_ch_77_cluster_2_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=77, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_77-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_77-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RAH_ch_77-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~1.2 MB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g1_77_RAH6_ch_77_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g2_77_RAH6_ch_77_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike/raster_UCLA_patient_482_p_g3_77_RAH6_ch_77_cluster_2_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=78, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=78, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=79, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=79, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []

--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike -patient 482 -channel 77 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike -patient 482 -channel 78 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike -patient 482 -channel 78 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike -patient 482 -channel 79 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike -patient 482 -channel 79 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro none --picks-macro none --picks-spike RAH --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RAH/spike
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/micro -patient 482 --micro-macro micro -channel 80 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/micro -patient 482 --micro-macro micro -channel 81 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/micro -patient 482 --micro-macro micro -channel 82 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/micro -patient 482 --micro-macro micro -channel 83 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/micro -patient 482 --micro-macro micro -channel 84 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/micro -patient 482 --micro-macro micro -channel 85 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/micro -patient 482 --micro-macro micro -channel 86 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/micro -patient 482 --micro-macro micro -channel 87 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro RIO --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/micro
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/macro -patient 482 --micro-macro macro -channel 74 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"Namespace(SOA=500, align=[], baseline=None, block=[], channel=80, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_80-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_80-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_80-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~573 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g1_80_RIO1_ch_80_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g2_80_RIO1_ch_80_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=80, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_80-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_80-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_80-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~854 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g1_80_RIO1_ch_80_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g2_80_RIO1_ch_80_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=81, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_81-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_81-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_81-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~289 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g1_81_RIO2_ch_81_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=81, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_81-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_81-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_81-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g1_81_RIO2_ch_81_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=82, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=82, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=83, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_83-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_83-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_83-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~856 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g1_83_RIO4_ch_83_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g2_83_RIO4_ch_83_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g3_83_RIO4_ch_83_cluster_2_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=83, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_83-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_83-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_83-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~1.2 MB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g1_83_RIO4_ch_83_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g2_83_RIO4_ch_83_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g3_83_RIO4_ch_83_cluster_2_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=84, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_84-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_84-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_84-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~856 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g1_84_RIO5_ch_84_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g2_84_RIO5_ch_84_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g3_84_RIO5_ch_84_cluster_2_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=84, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_84-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_84-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_84-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~1.2 MB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g1_84_RIO5_ch_84_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g2_84_RIO5_ch_84_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g3_84_RIO5_ch_84_cluster_2_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=85, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_85-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_85-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_85-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~289 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g1_85_RIO6_ch_85_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=85, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_85-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_85-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_85-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g1_85_RIO6_ch_85_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=86, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_86-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_86-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_86-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~573 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g1_86_RIO7_ch_86_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g2_86_RIO7_ch_86_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=86, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_86-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_86-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_86-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~854 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g1_86_RIO7_ch_86_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g2_86_RIO7_ch_86_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=87, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_87-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_87-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_87-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~289 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g1_87_RIO8_ch_87_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=87, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_87-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_87-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_RIO_ch_87-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike/raster_UCLA_patient_482_p_g1_87_RIO8_ch_87_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:

--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro RIO --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/micro
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike -patient 482 -channel 80 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike -patient 482 -channel 80 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike -patient 482 -channel 81 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike -patient 482 -channel 81 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike -patient 482 -channel 82 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike -patient 482 -channel 82 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike -patient 482 -channel 83 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike -patient 482 -channel 83 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike -patient 482 -channel 84 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike -patient 482 -channel 84 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike -patient 482 -channel 85 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike -patient 482 -channel 85 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike -patient 482 -channel 86 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike -patient 482 -channel 86 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike -patient 482 -channel 87 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike -patient 482 -channel 87 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro none --picks-macro none --picks-spike RIO --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/RIO/spike
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/micro -patient 482 --micro-macro micro -channel 57 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/micro -patient 482 --micro-macro micro -channel 58 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/micro -patient 482 --micro-macro micro -channel 59 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/micro -patient 482 --micro-macro micro -channel 60 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"Namespace(SOA=500, align=[], baseline=None, block=[], channel=57, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=57, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=58, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=58, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=59, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_59-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_59-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_59-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~1.4 MB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g1_59_LIO3_ch_59_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g2_59_LIO3_ch_59_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g3_59_LIO3_ch_59_cluster_2_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g4_59_LIO3_ch_59_cluster_3_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g5_59_LIO3_ch_59_cluster_4_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=59, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_59-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_59-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_59-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~2.1 MB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g1_59_LIO3_ch_59_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g2_59_LIO3_ch_59_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g3_59_LIO3_ch_59_cluster_2_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g4_59_LIO3_ch_59_cluster_3_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g5_59_LIO3_ch_59_cluster_4_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=60, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_60-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_60-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_60-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~289 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g1_60_LIO4_ch_60_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=60, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_60-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_60-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_60-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g1_60_LIO4_ch_60_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=61, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_61-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_61-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_61-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~856 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g1_61_LIO5_ch_61_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g3_61_LIO5_ch_61_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g4_61_LIO5_ch_61_cluster_2_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=61, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_61-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_61-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_61-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~1.2 MB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g1_61_LIO5_ch_61_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g3_61_LIO5_ch_61_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g4_61_LIO5_ch_61_cluster_2_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=62, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_62-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_62-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_62-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~573 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g1_62_LIO6_ch_62_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g2_62_LIO6_ch_62_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=62, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_62-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_62-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_62-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~854 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g1_62_LIO6_ch_62_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g2_62_LIO6_ch_62_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=63, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_63-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_63-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_63-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~289 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g1_63_LIO7_ch_63_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:

--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/micro -patient 482 --micro-macro micro -channel 61 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/micro -patient 482 --micro-macro micro -channel 62 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/micro -patient 482 --micro-macro micro -channel 63 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/micro -patient 482 --micro-macro micro -channel 64 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro LIO --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/micro
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/macro -patient 482 --micro-macro macro -channel 22 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro LIO --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/micro
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike -patient 482 -channel 57 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike -patient 482 -channel 57 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike -patient 482 -channel 58 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike -patient 482 -channel 58 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike -patient 482 -channel 59 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike -patient 482 -channel 59 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike -patient 482 -channel 60 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike -patient 482 -channel 60 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike -patient 482 -channel 61 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike -patient 482 -channel 61 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike -patient 482 -channel 62 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike -patient 482 -channel 62 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike -patient 482 -channel 63 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike -patient 482 -channel 63 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"Namespace(SOA=500, align=[], baseline=None, block=[], channel=63, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_63-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_63-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIO_ch_63-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike/raster_UCLA_patient_482_p_g1_63_LIO7_ch_63_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=64, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=64, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=41, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_41-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_41-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_41-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~573 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike/raster_UCLA_patient_482_p_g1_41_LIP1_ch_41_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike/raster_UCLA_patient_482_p_g2_41_LIP1_ch_41_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:

--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike -patient 482 -channel 64 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike -patient 482 -channel 64 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro none --picks-macro none --picks-spike LIO --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIO/spike
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/micro -patient 482 --micro-macro micro -channel 41 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/micro -patient 482 --micro-macro micro -channel 42 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/micro -patient 482 --micro-macro micro -channel 43 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/micro -patient 482 --micro-macro micro -channel 44 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/micro -patient 482 --micro-macro micro -channel 45 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/micro -patient 482 --micro-macro micro -channel 46 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/micro -patient 482 --micro-macro micro -channel 47 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/micro -patient 482 --micro-macro micro -channel 48 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro LIP --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/micro
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/macro -patient 482 --micro-macro macro -channel 30 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro LIP --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/micro
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike -patient 482 -channel 41 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------Namespace(SOA=500, align=[], baseline=None, block=[], channel=41, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_41-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_41-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_41-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~854 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike/raster_UCLA_patient_482_p_g1_41_LIP1_ch_41_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike/raster_UCLA_patient_482_p_g2_41_LIP1_ch_41_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=42, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=42, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=43, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_43-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_43-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_43-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~289 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike/raster_UCLA_patient_482_p_g1_43_LIP3_ch_43_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=43, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_43-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_43-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_43-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike/raster_UCLA_patient_482_p_g1_43_LIP3_ch_43_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=44, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_44-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_44-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_44-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~573 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike/raster_UCLA_patient_482_p_g1_44_LIP4_ch_44_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike/raster_UCLA_patient_482_p_g2_44_LIP4_ch_44_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=44, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_44-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_44-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_44-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~854 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike/raster_UCLA_patient_482_p_g1_44_LIP4_ch_44_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike/raster_UCLA_patient_482_p_g2_44_LIP4_ch_44_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=45, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_45-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_45-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_45-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~573 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike/raster_UCLA_patient_482_p_g1_45_LIP5_ch_45_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike/raster_UCLA_patient_482_p_g2_45_LIP5_ch_45_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=45, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_45-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_45-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LIP_ch_45-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~854 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike/raster_UCLA_patient_482_p_g1_45_LIP5_ch_45_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike/raster_UCLA_patient_482_p_g2_45_LIP5_ch_45_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=46, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=46, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=47, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=47, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=48, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=48, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []

python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike -patient 482 -channel 41 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike -patient 482 -channel 42 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike -patient 482 -channel 42 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike -patient 482 -channel 43 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike -patient 482 -channel 43 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike -patient 482 -channel 44 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike -patient 482 -channel 44 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike -patient 482 -channel 45 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike -patient 482 -channel 45 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike -patient 482 -channel 46 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike -patient 482 -channel 46 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike -patient 482 -channel 47 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike -patient 482 -channel 47 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike -patient 482 -channel 48 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike -patient 482 -channel 48 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro none --picks-macro none --picks-spike LIP --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LIP/spike
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/micro -patient 482 --micro-macro micro -channel 33 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/micro -patient 482 --micro-macro micro -channel 34 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/micro -patient 482 --micro-macro micro -channel 35 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/micro -patient 482 --micro-macro micro -channel 36 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/micro -patient 482 --micro-macro micro -channel 37 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"Namespace(SOA=500, align=[], baseline=None, block=[], channel=33, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=33, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=34, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LSTG_ch_34-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LSTG_ch_34-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LSTG_ch_34-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~290 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike/raster_UCLA_patient_482_p_g1_34_LSTG2_ch_34_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=34, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LSTG_ch_34-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LSTG_ch_34-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LSTG_ch_34-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike/raster_UCLA_patient_482_p_g1_34_LSTG2_ch_34_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=35, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=35, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=36, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=36, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=37, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=37, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=38, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=38, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=39, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=39, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=40, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []

--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/micro -patient 482 --micro-macro micro -channel 38 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/micro -patient 482 --micro-macro micro -channel 39 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/micro -patient 482 --micro-macro micro -channel 40 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro LSTG --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/micro
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/macro -patient 482 --micro-macro macro -channel 53 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro LSTG --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/micro
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike -patient 482 -channel 33 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike -patient 482 -channel 33 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike -patient 482 -channel 34 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike -patient 482 -channel 34 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike -patient 482 -channel 35 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike -patient 482 -channel 35 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike -patient 482 -channel 36 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike -patient 482 -channel 36 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike -patient 482 -channel 37 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike -patient 482 -channel 37 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike -patient 482 -channel 38 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike -patient 482 -channel 38 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike -patient 482 -channel 39 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike -patient 482 -channel 39 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike -patient 482 -channel 40 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike -patient 482 -channel 40 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"Namespace(SOA=500, align=[], baseline=None, block=[], channel=40, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=65, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=65, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=66, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_REC_ch_66-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_REC_ch_66-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_REC_ch_66-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~289 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike/raster_UCLA_patient_482_p_g1_66_REC2_ch_66_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:

--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro none --picks-macro none --picks-spike LSTG --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LSTG/spike
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/micro -patient 482 --micro-macro micro -channel 65 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/micro -patient 482 --micro-macro micro -channel 66 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/micro -patient 482 --micro-macro micro -channel 67 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/micro -patient 482 --micro-macro micro -channel 68 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/micro -patient 482 --micro-macro micro -channel 69 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/micro -patient 482 --micro-macro micro -channel 70 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/micro -patient 482 --micro-macro micro -channel 71 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/micro -patient 482 --micro-macro micro -channel 72 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro REC --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/micro
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/macro -patient 482 --micro-macro macro -channel 67 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro REC --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/micro
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike -patient 482 -channel 65 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike -patient 482 -channel 65 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike -patient 482 -channel 66 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------Namespace(SOA=500, align=[], baseline=None, block=[], channel=66, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_REC_ch_66-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_REC_ch_66-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_REC_ch_66-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike/raster_UCLA_patient_482_p_g1_66_REC2_ch_66_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=67, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=67, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=68, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=68, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=69, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=69, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=70, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=70, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=71, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=71, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=72, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=72, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []

python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike -patient 482 -channel 66 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike -patient 482 -channel 67 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike -patient 482 -channel 67 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike -patient 482 -channel 68 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike -patient 482 -channel 68 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike -patient 482 -channel 69 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike -patient 482 -channel 69 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike -patient 482 -channel 70 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike -patient 482 -channel 70 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike -patient 482 -channel 71 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike -patient 482 -channel 71 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike -patient 482 -channel 72 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike -patient 482 -channel 72 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro none --picks-macro none --picks-spike REC --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/REC/spike
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/micro -patient 482 --micro-macro micro -channel 49 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/micro -patient 482 --micro-macro micro -channel 50 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/micro -patient 482 --micro-macro micro -channel 51 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/micro -patient 482 --micro-macro micro -channel 52 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/micro -patient 482 --micro-macro micro -channel 53 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/micro -patient 482 --micro-macro micro -channel 54 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"Namespace(SOA=500, align=[], baseline=None, block=[], channel=49, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_49-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_49-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_49-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~289 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike/raster_UCLA_patient_482_p_g1_49_LO1_ch_49_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=49, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_49-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_49-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_49-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike/raster_UCLA_patient_482_p_g1_49_LO1_ch_49_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=50, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_50-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_50-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_50-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~573 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike/raster_UCLA_patient_482_p_g1_50_LO2_ch_50_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike/raster_UCLA_patient_482_p_g2_50_LO2_ch_50_cluster_1_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=50, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_50-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_50-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_50-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~854 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike/raster_UCLA_patient_482_p_g1_50_LO2_ch_50_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike/raster_UCLA_patient_482_p_g2_50_LO2_ch_50_cluster_1_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=51, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=51, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=52, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=52, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=53, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=53, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=54, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_54-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_54-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_54-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   24 events (all good), -0.5 - 1 sec, baseline off, ~289 kB, data loaded, with metadata,
 'block_2': 8
 'block_4': 8
 'block_6': 8>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike/raster_UCLA_patient_482_p_g1_54_LO6_ch_54_cluster_0_Embedding == 1 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=54, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: ['../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_54-epo.fif']
Loading epochs object: ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_54-epo.fif
Reading ../../Data/UCLA/patient_482/Epochs/patient_482_spikes_LO_ch_54-epo.fif ...
Isotrak not found
    Found the data of interest:
        t =   -3000.00 ...    3000.00 ms
        0 CTF compensation matrices available
3960 matching events found
No baseline correction applied
Adding metadata with 94 columns
0 projection items activated
<EpochsFIF  |   36 events (all good), -0.5 - 1 sec, baseline off, ~430 kB, data loaded, with metadata,
 'block_2': 12
 'block_4': 12
 'block_6': 12>
Sampling rate: 1000.00
Figures saved to ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike/raster_UCLA_patient_482_p_g1_54_LO6_ch_54_cluster_0_Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]_word_stringSorted.png:
Namespace(SOA=500, align=[], baseline=None, block=[], channel=55, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=55, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=56, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike', patient='patient_482', queries_to_compare=[], query='Embedding == 1 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []
Namespace(SOA=500, align=[], baseline=None, block=[], channel=56, hospital='UCLA', path2figures='../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike', patient='patient_482', queries_to_compare=[], query='Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]', sort_cluster=False, sort_key=['word_string'], tmax=1, tmin=-0.5, window_ed=200, window_st=0, word_ON_duration=250, y_tick_step=10, ylim_PSTH=20)
Loading: []

--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/micro -patient 482 --micro-macro micro -channel 55 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/micro -patient 482 --micro-macro micro -channel 56 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro LO --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/micro
--------------------------------------------------------------------------------
python plot_evoked_comparison.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/macro -patient 482 --micro-macro macro -channel 38 --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]" --queries-to-compare Embedding "Embedding == 1 and word_position==-1 and block in [1, 3, 5]" --queries-to-compare Long_declarative "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [1, 3, 5]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro LO --picks-macro none --picks-spike none --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/micro
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike -patient 482 -channel 49 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike -patient 482 -channel 49 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike -patient 482 -channel 50 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike -patient 482 -channel 50 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike -patient 482 -channel 51 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike -patient 482 -channel 51 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike -patient 482 -channel 52 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike -patient 482 -channel 52 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike -patient 482 -channel 53 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike -patient 482 -channel 53 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike -patient 482 -channel 54 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike -patient 482 -channel 54 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike -patient 482 -channel 55 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike -patient 482 -channel 55 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike -patient 482 -channel 56 --query "Embedding == 1 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python plot_rasters.py --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike -patient 482 -channel 56 --query "Declarative==1 and sentence_length==5 and Embedding==0 and word_position==-1 and block in [2, 4, 6]"
--------------------------------------------------------------------------------
python run_GAT.py -p 482 --cat-k-timepoint 1 -c 33 --picks-micro none --picks-macro none --picks-spike LO --path2figures ../../Figures/Comparisons/33_embedding_audio2visual/patient_482/LO/spike
--------------------------------------------------------------------------------
dict_keys(['LEC', 'LPHG', 'LAH', 'LA', 'RAH', 'RIO', 'LIO', 'LIP', 'LSTG', 'REC', 'LO', 'MICROPHONE'])
